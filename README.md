**Programming for Data Analysis 2020 Submission**

**GMIT Higher Diploma in Data Analytics**

**Submitted by Fiona Lee - 3 December 2021**

**Introduction**

This project creates and models a simulated data set related to the factors underlying the length of stay of dogs in animal shelters using the numpy.random package in Python. 

![alt text](https://i1.wp.com/puppytoob.com/wp-content/uploads/2017/07/Pet-Shelters.jpg?w=600&ssl=1)

*Source: https://i1.wp.com/puppytoob.com/wp-content/uploads/2017/07/Pet-Shelters.jpg?w=600&ssl=1*

**Qualities and attributes of the dataset**

The dataset contains 200 samples (rows), and 5 variables (columns) named; Duration (Days), Age_Yrs, Gender, Pedigree and Size, and species  

For each sample, five features/variables were measured i.e. 

  -	Duration (Days): Number of days a dog stays in the shelter from entry to adoption, foster or euthenasia
  -	Age_Yrs: Age in years rounded to nearest year
  -	Gender: Sex of the animal (male or female)
  -	Pedigree: Pedigree of the animal (purebred or crossbreed)
  - Size: Size of the animal (small, medium or large) 

**Detailed Analysis - Initial Findings**

The detailed results of the initial analysis on ‘Animal Shelter Data Set’ are contained in the Final Project.ipynb file.

*Repository Link: https://github.com/Fiona-600/Programming-for-Data-Analytics-2020-Project/blob/main/Final%20Project.ipynb*

A summary of the assumptions behind the dataset are detailed below:

*Age*

The age profile of dogs in the dataset are broken down as follows: 

Puppy (<1 years) 36%; Adult (1-3 years) 29%; Adult (4-6 years) 19% Senior (7+) 16%

<6 mths 14%; 6-12 mths 22%; 1 year 12%; 2 years 11%; 3 years 6%; 4 years 8%; 5 years 7%; 6 years 4%; 7-9 years+ 13%; 10 yrs+ 3% (Extrapolated from US Study)

*Gender*

The split of male to female dogs was 57% male and 43% female.

*Pedigree*

The split of pedigree / crossbreed dogs was 21% pedigree and 79% crossbreed dogs.

*Size*

The split of pedigree / crossbreed dogs based on 2,806 dogs in the 'Dogs Trust dataset' was 22% small (<10kg), 60% medium (10-30kg) and 18% large (>30kg).

*Length of Stay (Duration (Days))*

The average adoption time - 29 days

*The Mean, Median, Standard Deviation, Min and Max Values by Species are contained in the Final Project.ipynb file*

*Repository Link: https://github.com/Fiona-600/Programming-for-Data-Analytics-2020-Project/blob/main/Final%20Project.ipynb*

**Purpose of the project**

The presentation will include:

This project creates and models a simulated data set related to a chosen real-world phenomenon using the numpy.random package in Python. This approach is taken rather than collecting the data.

The elements explored will be:

1.	An explanation of what investigating a data set entails
2.	Investigate the types of variables involved, their likely distributions, and their relationships with each other.
3.	Synthesise/simulate a data set as closely matching their properties as possible.
4.	Detail your research and implement the simulation in a Jupyter notebook – the data set itself can simply be displayed in an output cell   within the notebook.

**Structure & Project Navigation**

The project will be stored in a GITHUB Repository at url: https://github.com/Fiona-600/Programming-for-Data-Analytics-2020-Project.git

1.	The GITHUB repository will contain:

    •	A ‘LICENSE’ file containing a copy of the MIT Licence

    •	A ‘README.md’ file which contains:

          •	The data set itself
          •	Online and other research into the data set
          •	Investigations into the data set
          •	How to run the python code
          •	What that code does.
          •	All references used in completing the project

    •	A python program file called ‘FinalProject.ipynb’ which will:

          1.  
          2.  
          3.  

**Technology Used**

**Required Programs**

	•	Anaconda Navigator 3
	•	Visual Studio Code
	•	Python version 3.7.4
  •	Cmder 
	•	GitHub
 	•	MS Office 
	•	Firefox Internet Explorer

**Procedure for downloading required programs**

    •	Python version 3.7.4 was downloaded via Anaconda Navigator 3 to Windows 10 OS (https://www.anaconda.com/).
    •	Microsoft Visual Studio Code was downloaded (https://code.visualstudio.com/).
    •	Microsoft Visual Studio Code was configurated with GitHub (https://github.com/).
    •	The Iris dataset was imported to Python as a CSV file 


**Libraries and Modules**

    •	NumPy - ‘import numpy as np’

    •	Pandas – ‘import pandas as pd’
        
    •	Matplotlib - ‘import matplotlib.pyplot as plt’

    •	Seaborn - ‘import seaborn as sns’, 'sms.set'



**Author & Contributors**

Fiona Lee



**License**

This project is licensed under the MIT License - see the LICENSE.md file for details



**Acknowledgments**

Brian McGinley and Ian McLoughlin for all the helpful tips in completing these assignments



**References**

